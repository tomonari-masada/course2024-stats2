{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2024-stats2/blob/main/02_introduction_to_JAX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bCTE9ku1vWN"
      },
      "source": [
        "# JAX+Flax入門\n",
        "\n",
        "* このnotebookは、以下のthe University of Amsterdamの講義資料を元に作成した。\n",
        " * Phillip Lippe, [Tutorial 2 (JAX): Introduction to JAX+Flax](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial2/Introduction_to_JAX.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ISs7P_P1vWP"
      },
      "source": [
        "* JAXのPros\n",
        " * コードの見た目がNumPyとそっくり。\n",
        " * just-in-time (JIT) コンパイラでGPUやTPUのハードウェアとしての能力を最大限に利用できる。\n",
        " * コンパイル時にコードの最適化も行われる。\n",
        " * 一定の制約を満たせば、いったんコンパイルした効率の良いコードを、何度でも使いまわせる。\n",
        "\n",
        "* JAXのCons\n",
        " * JITコンパイラを使えるようなコードを書かなければならない。例えば・・・\n",
        " * **side-effectのある関数（namespaceの外側に影響を与える関数）は扱えない。**\n",
        "   * cf. https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html\n",
        " * このため、疑似乱数の扱いもやや煩雑となる。\n",
        " * **条件によって演算の対象となる配列やテンソルの形が変わる処理は扱えない。**（例：`y = x[x>3]`)\n",
        "\n",
        "* とはいえ、深層学習で使われる多くの計算は、JAXのJIT compilingの制約を満たす。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JAX+Flaxの入門として参考になるWebページ\n",
        " * [JAX 101](https://jax.readthedocs.io/en/latest/jax-101/index.html)\n",
        " * [JAX - The Sharp Bits](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html)\n"
      ],
      "metadata": {
        "id": "MxMhtUTB5Maa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Flax](https://flax.readthedocs.io/en/latest/) はJAXの深層学習ライブラリ。\n",
        " * 参考： [Flax Basics](https://flax.readthedocs.io/en/latest/notebooks/flax_basics.html)\n",
        "\n",
        "* [Optax](https://optax.readthedocs.io/en/latest/index.html) は深層学習でよく使われるoptimizerをJAXで実装したもの。"
      ],
      "metadata": {
        "id": "RF8WG_dp6Z2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JAXはPyTorchのDataLoaderやTensorFlowのTensorBoardと組み合わせて使える。\n",
        " * 深層学習モデルの定義や学習の部分だけ、JAXに置き換えればよい。\n"
      ],
      "metadata": {
        "id": "TaVFj_4S5b8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 準備\n",
        "* 最初に、ランタイムのタイプをGPUに設定してください。"
      ],
      "metadata": {
        "id": "jPam_loQ7T81"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G94NqIKK1vWQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IYcmg8i1vWR"
      },
      "source": [
        "## アクセラレータ上のNumPyとしてのJAX\n",
        "\n",
        "* JAXの基本的なAPIはNumPyと、そっくり。\n",
        "* 名前も同じ (`jax.numpy`)。\n",
        "* というわけで、とりあえずはJAXをアクセラレータ上で走るNumPyとみなしてよい。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIkooaBU1vWR"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "print(\"Using jax\", jax.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8YQ9XQk1vWS"
      },
      "source": [
        "### JAXの配列"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 配列の作り方はNumPyとほとんど同じ。"
      ],
      "metadata": {
        "id": "QWkbEZfF8ZOH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXolsg1i1vWT"
      },
      "outputs": [],
      "source": [
        "a = jnp.zeros((2, 5), dtype=jnp.float32)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asa70Xhl1vWT"
      },
      "outputs": [],
      "source": [
        "b = jnp.arange(6)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLjJj2nn1vWU"
      },
      "source": [
        "* だが、classは異なる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTPzXvsC1vWU"
      },
      "outputs": [],
      "source": [
        "b.__class__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYvjlsli1vWU"
      },
      "source": [
        "* JAXの配列は、CPU, GPU, TPUのいずれでも使える。\n",
        "* PyTorchのように、`.device()`で、どのデバイスにあるかを調べられる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHafNCa21vWU"
      },
      "outputs": [],
      "source": [
        "b.devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otiHUc-_1vWV"
      },
      "source": [
        "* このようにJAXでは配列がデフォルトでGPU上に作られる。\n",
        "* 配列のデバイスをCPUへ変えるには、`jax.device_get`を使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5pEBOoa1vWV"
      },
      "outputs": [],
      "source": [
        "b_cpu = jax.device_get(b)\n",
        "print(b_cpu.__class__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m5Rxqd21vWV"
      },
      "source": [
        "* CPU上に持ってきた配列は、NumPyの`ndarray`になる。\n",
        "* 逆に、NumPyの配列をアクセラレータに移動させるには、`jax.device_put`を使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCpckk2L1vWV"
      },
      "outputs": [],
      "source": [
        "b_gpu = jax.device_put(b_cpu)\n",
        "print(f'Device put: {b_gpu.__class__} on {b_gpu.devices()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sagjplF1vWV"
      },
      "source": [
        "* CPUとGPUにある配列を混在させると、デフォルトで計算結果はGPUに置かれる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwZoiINN1vWW"
      },
      "outputs": [],
      "source": [
        "(b_cpu + b_gpu).devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNlwnH4z1vWW"
      },
      "source": [
        "* 利用可能なデバイス一覧を`jax.devices()`で取得できる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xzbi2Jq1vWW"
      },
      "outputs": [],
      "source": [
        "jax.devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTmzWnjx1vWX"
      },
      "source": [
        "### JAXにおける擬似乱数\n",
        "\n",
        "* 計算機が生成する乱数は、本物の乱数ではなく、擬似乱数である。\n",
        "* 擬似乱数は、現在の状態をもとに、deterministicな計算によって生成される。\n",
        " * そして、次の乱数発生で使われる状態も、現在の状態からdeterministicに算出される。\n",
        "* 擬似乱数の生成は、全てdeterministicな計算によって進行するので、初期値であるシードが同じなら、必ず同じ乱数列が生成される。\n",
        "\n",
        "* JAXでは、擬似乱数を生成するたびに状態が次から次へと遷移するという、この擬似乱数生成の特徴が、関数を書く上で問題となる。\n",
        "* というのも、NumPyやPyTorchと同じように、関数の中で乱数を発生させると、関数の外側に影響を与えてしまうからである。\n",
        "* このように、外側に影響を与える関数は、JAXの考え方に馴染まない。\n",
        "* そこで、JAXでは、その中で乱数を使う関数に対して、明示的に擬似乱数の状態を渡すのが、コードを書く上での流儀となっている。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* まず、シード`42`に対するPRNG stateを、次のように作成する。"
      ],
      "metadata": {
        "id": "N241D8ZeGXBa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAAPGlxv1vWX"
      },
      "outputs": [],
      "source": [
        "key = jax.random.PRNGKey(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkcmlIb91vWX"
      },
      "source": [
        "* そして、このPRNG stateを乱数の生成に使う。\n",
        "* 以下のセルを実行し、JAXとNumPyの違いを確認しよう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7HDoKSO1vWX"
      },
      "outputs": [],
      "source": [
        "# JAXで乱数を生成する望ましくない方法\n",
        "jax_random_number_1 = jax.random.normal(key)\n",
        "jax_random_number_2 = jax.random.normal(key)\n",
        "print('JAX - Random number 1:', jax_random_number_1)\n",
        "print('JAX - Random number 2:', jax_random_number_2)\n",
        "\n",
        "# NumPyでは典型的には以下のように乱数を生成する\n",
        "np.random.seed(42)\n",
        "np_random_number_1 = np.random.normal()\n",
        "np_random_number_2 = np.random.normal()\n",
        "print('NumPy - Random number 1:', np_random_number_1)\n",
        "print('NumPy - Random number 2:', np_random_number_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIosrUj01vWX"
      },
      "source": [
        "* NumPyのように乱数を発生させたいとき、JAXでは、PRNG stateを分岐(split)する。\n",
        "* そして、splitすることで得られたsubkeyを、乱数を発生させる関数に渡す。\n",
        " * 乱数のkeyのsplitには`jax.random.split(...)`を使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMxzsLz01vWX"
      },
      "outputs": [],
      "source": [
        "key, key_ = jax.random.split(key)\n",
        "jax_random_number_1 = jax.random.normal(key_)\n",
        "key, key_ = jax.random.split(key)\n",
        "jax_random_number_2 = jax.random.normal(key_)\n",
        "print('JAX new - Random number 1:', jax_random_number_1)\n",
        "print('JAX new - Random number 2:', jax_random_number_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD-Vt2wk1vWX"
      },
      "source": [
        "* 上のセルを繰り返し実行すると、その度に異なる乱数を得る。\n",
        "* このようにJAXでは、**乱数を生成させる前にPRNG keyをsplitする**。\n",
        " * cf. JAX's tutorial on [Pseudo Random Numbers](https://jax.readthedocs.io/en/latest/jax-101/05-random-numbers.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpRFYeqm1vWY"
      },
      "source": [
        "### 自動微分\n",
        "* JAXでは自動微分が使える。\n",
        " * 自動微分について、PyTorchやTensorFlowを代替するライブラリとして利用できる。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 関数の例\n",
        "$$ y = \\frac{1}{N}\\sum_{i=1}^N\\left[\\left(x_i+2\\right)^2+3\\right]$$"
      ],
      "metadata": {
        "id": "BRnZYOQt20uL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkOjB8UX1vWY"
      },
      "outputs": [],
      "source": [
        "def simple_graph(x):\n",
        "  x = x + 2\n",
        "  x = x ** 2\n",
        "  x = x + 3\n",
        "  y = x.mean()\n",
        "  return y\n",
        "\n",
        "inp = jnp.arange(3, dtype=jnp.float32)\n",
        "print('Input', inp)\n",
        "print('Output', simple_graph(inp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DAjLr3w1vWY"
      },
      "source": [
        "* PyTorchでの計算グラフに相当するものは、JAXでは\n",
        "Jaxprと呼ばれる。\n",
        " * あえて訳すと「JAX表示式」？\n",
        " * cf. https://jax.readthedocs.io/en/latest/jaxpr.html\n",
        "* `jax.make_jaxpr`を使えば、関数のjaxprが得られる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfAjUKUj1vWY"
      },
      "outputs": [],
      "source": [
        "jax.make_jaxpr(simple_graph)(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 入力として与える配列の形を変えると、得られるjaxprも変わる。"
      ],
      "metadata": {
        "id": "xN2LYGemNnd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp2 = jnp.ones((3, 3), dtype=jnp.float32)\n",
        "jax.make_jaxpr(simple_graph)(inp2)"
      ],
      "metadata": {
        "id": "gnY1c4fVNa0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 自動微分には`jax.grad`を使う。\n",
        " * 自動微分は、関数をtransformして別の関数を得ること、とみなせる。"
      ],
      "metadata": {
        "id": "qe3NRb1bO5S5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4_1clqw1vWZ"
      },
      "outputs": [],
      "source": [
        "grad_function = jax.grad(simple_graph)\n",
        "gradients = grad_function(inp)\n",
        "print('Gradient', gradients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvVpl9HE1vWZ"
      },
      "source": [
        "* 勾配だけでなく、関数の出力値も得たいときは`jax.value_and_grad`を使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS__oi4h1vWZ"
      },
      "outputs": [],
      "source": [
        "val_grad_function = jax.value_and_grad(simple_graph)\n",
        "val_grad_function(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRtzeUgG1vWa"
      },
      "source": [
        "### Just-In-Timeコンパイラ\n",
        "\n",
        "* JAXには、関数をjust-in-timeでコンパイルする機能が備わっている。\n",
        " * コンパイルは、与えられた関数をより高速に実行できる関数へとtransformすること、とみなせる。\n",
        "* JITコンパイルには`jax.jit`を使う。\n",
        " * もしくは、関数の直前で`@jax.jit`というデコレータを用いる。\n",
        "* コンパイルされた関数は、XLAにより高速化される。\n",
        " * https://www.tensorflow.org/xla?hl=ja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLByUDa01vWa"
      },
      "outputs": [],
      "source": [
        "jitted_function = jax.jit(simple_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* コンパイルするとどのくらい実行が高速化されるのか、調べる。"
      ],
      "metadata": {
        "id": "fEgun39HRqVE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV6OaLnD1vWa"
      },
      "outputs": [],
      "source": [
        "# Create a new random subkey for generating new random values\n",
        "key, key_ = jax.random.split(key)\n",
        "large_input = jax.random.normal(key_, (10000,))\n",
        "# Run the jitted function once to start compilation\n",
        "_ = jitted_function(large_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* JAXは、デフォルトで非同期に計算を行う。\n",
        " * 計算結果を収める場所だけ先に作っておいて、計算され次第、そこに答えを埋めていく、という感じ。\n",
        "* そのため、計算の実行時間を測るときは`block_until_ready()`が必要。"
      ],
      "metadata": {
        "id": "Bn1rneom5B5k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH7eC9fF1vWa"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "simple_graph(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXK1NI1m1vWa"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "jitted_function(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 微分した結果得られた関数も、コンパイルできる。"
      ],
      "metadata": {
        "id": "1mBPM7Et5dUJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M67dePAe1vWa"
      },
      "outputs": [],
      "source": [
        "jitted_grad_function = jax.jit(grad_function)\n",
        "_ = jitted_grad_function(large_input)  # Apply once to compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRfbxTG61vWb"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "grad_function(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8ep9wMx1vWb"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "jitted_grad_function(large_input).block_until_ready()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yrZo72D1vWb"
      },
      "source": [
        "## Flax\n",
        "* JAXだけ使っても、複雑なニューラルネットワークを実装することはできる。\n",
        "* しかし、非常に煩雑な作業になる。\n",
        "* そこで、深層学習むけのコードを書くときには、専用のライブラリを使う。\n",
        "\n",
        " * [Flax](https://flax.readthedocs.io/en/latest/index.html), started by the Google Brain Team, focuses on flexibility and clarity.\n",
        " * [Trax](https://github.com/google/trax), maintained by the Google Brain Team, provides solutions for common training tasks\n",
        " * [Equinox](https://github.com/patrick-kidger/equinox), created by Patrick Kidger and Cristian Garcia, implements neural networks as callable PyTrees\n",
        "\n",
        "* ここではFlaxを使う。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 以下のようなデータセット(XOR)を二値分類するMLPのtrainingを、Flaxで書いてみる。\n",
        "\n",
        "<center style=\"width: 100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/continuous_xor.svg?raw=1\" width=\"350px\"></center>"
      ],
      "metadata": {
        "id": "biuU3heT6EcJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_UpIXYn1vWb"
      },
      "source": [
        "### モデルの定義\n",
        "\n",
        "* `flax.linen`が便利。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import flax\n",
        "from flax import linen as nn"
      ],
      "metadata": {
        "id": "U7PJSIu8R4oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqxUUkKt1vWb"
      },
      "source": [
        "#### Flaxの`nn.Module`\n",
        "\n",
        "* PyTorchの`nn.Module`と似ている。\n",
        "* 簡単なMLPの実装例を、下に示す。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUhvLog71vWc"
      },
      "source": [
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/small_neural_network.svg?raw=1\" width=\"300px\"></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwzOArTg1vWc"
      },
      "outputs": [],
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "  num_hidden : int   # Number of hidden neurons\n",
        "  num_outputs : int  # Number of output neurons\n",
        "\n",
        "  def setup(self):\n",
        "    # Create the modules we need to build the network\n",
        "    # nn.Dense is a linear layer\n",
        "    self.linear1 = nn.Dense(features=self.num_hidden)\n",
        "    self.linear2 = nn.Dense(features=self.num_outputs)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # Perform the calculation of the model to determine the prediction\n",
        "    x = self.linear1(x)\n",
        "    x = nn.tanh(x)\n",
        "    x = self.linear2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-dN48er1vWc"
      },
      "outputs": [],
      "source": [
        "model = SimpleClassifier(num_hidden=8, num_outputs=1)\n",
        "# Printing the model shows its attributes\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* モデルそのものと、モデル・パラメータの値の特定の設定とは、別々に扱う。"
      ],
      "metadata": {
        "id": "eiFIPt8-WTjr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjEqaM771vWc"
      },
      "outputs": [],
      "source": [
        "key, key_ = jax.random.split(key)\n",
        "inp = jax.random.normal(key_, (8, 2))  # Batch size 8, input size 2\n",
        "# Initialize the model\n",
        "key, key_ = jax.random.split(key)\n",
        "params = model.init(key_, inp)\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd4-Gs8g1vWc"
      },
      "source": [
        "* 特定の入力に対する出力を得るときは、モデルパラメータの値の特定の設定も、同時に指定する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrAK7HBW1vWd"
      },
      "outputs": [],
      "source": [
        "model.apply(params, inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4xSnO8i1vWd"
      },
      "source": [
        "### データの準備\n",
        "* データを扱うためのコードだけ、別途PyTorchで書くことができる。\n",
        "  * https://jax.readthedocs.io/en/latest/notebooks/Neural_Network_and_Data_Loading.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cE3_sU71vWd"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### データセット"
      ],
      "metadata": {
        "id": "b6iqhZumZLy4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EExjIqXM1vWd"
      },
      "outputs": [],
      "source": [
        "class XORDataset(data.Dataset):\n",
        "\n",
        "  def __init__(self, size, seed, std=0.1):\n",
        "    super().__init__()\n",
        "    self.size = size\n",
        "    self.np_rng = np.random.RandomState(seed=seed)\n",
        "    self.std = std\n",
        "    self.generate_continuous_xor()\n",
        "\n",
        "  def generate_continuous_xor(self):\n",
        "    data = self.np_rng.randint(low=0, high=2, size=(self.size, 2)).astype(np.float32)\n",
        "    label = (data.sum(axis=1) == 1).astype(np.int32)\n",
        "    # 0.0か1.0のいずれかであるデータにノイズを追加して問題を難しくする。\n",
        "    data += self.np_rng.normal(loc=0.0, scale=self.std, size=data.shape)\n",
        "    self.data = data\n",
        "    self.label = label\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx], self.label[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUMwoG8X1vWd"
      },
      "outputs": [],
      "source": [
        "dataset = XORDataset(size=200, seed=42)\n",
        "print(\"Size of dataset:\", len(dataset))\n",
        "print(\"Data point 0:\", dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5EEm1d_1vWe"
      },
      "outputs": [],
      "source": [
        "def visualize_samples(data, label):\n",
        "  data_0 = data[label == 0]\n",
        "  data_1 = data[label == 1]\n",
        "\n",
        "  plt.figure(figsize=(4, 4))\n",
        "  plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "  plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "  plt.title(\"Dataset samples\")\n",
        "  plt.ylabel(r\"$x_2$\")\n",
        "  plt.xlabel(r\"$x_1$\")\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ywMvJQI1vWe"
      },
      "outputs": [],
      "source": [
        "visualize_samples(dataset.data, dataset.label);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUyINWEq1vWe"
      },
      "source": [
        "#### データローダ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* データをNumPyの配列に変換するcollate関数"
      ],
      "metadata": {
        "id": "-3eiEz36ODbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.tree_util import tree_map\n",
        "\n",
        "def numpy_collate(batch):\n",
        "  return tree_map(np.asarray, data.default_collate(batch))"
      ],
      "metadata": {
        "id": "rleesTQVMk_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* PyTorchのデータローダを作成"
      ],
      "metadata": {
        "id": "dA0agXRHOJWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = data.DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=numpy_collate)"
      ],
      "metadata": {
        "id": "M8aL7K9kMr33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 試しに、一つ、ミニバッチを取得してみる。"
      ],
      "metadata": {
        "id": "EHCYj1OQOMB7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyvqCdJ11vWe"
      },
      "outputs": [],
      "source": [
        "data_inputs, data_labels = next(iter(data_loader))\n",
        "print(\"Data inputs\", data_inputs.shape, \"\\n\", data_inputs)\n",
        "print(\"Data labels\", data_labels.shape, \"\\n\", data_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LKzDUzK1vWe"
      },
      "source": [
        "### 最適化アルゴリズム\n",
        "* `optax`というライブラリを使う。\n",
        " * https://optax.readthedocs.io/en/latest/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "\n",
        "optimizer = optax.sgd(learning_rate=0.1)"
      ],
      "metadata": {
        "id": "A-WRNNc2Ubjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 訓練の状態を初期化する。"
      ],
      "metadata": {
        "id": "qpermNTQXLM9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6_3rLb-1vWf"
      },
      "outputs": [],
      "source": [
        "from flax.training import train_state\n",
        "\n",
        "model_state = train_state.TrainState.create(\n",
        "    apply_fn=model.apply,\n",
        "    params=params,\n",
        "    tx=optimizer,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jsIXSyo1vWf"
      },
      "source": [
        "### 損失関数\n",
        "\n",
        "* `optax`に実装されているものを使う。\n",
        "* 二値分類なので、クロスエントロピーを損失関数として使う。\n",
        "  * $y$はラベル。$x$は予測。\n",
        "\n",
        "$$L_{BCE} = -\\sum_i \\left[ y_i \\log x_i + (1 - y_i) \\log (1 - x_i) \\right]$$\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIkQbBbY1vWf"
      },
      "outputs": [],
      "source": [
        "def calculate_loss_acc(state, params, batch):\n",
        "  data_input, labels = batch\n",
        "  # Obtain the logits and predictions of the model for the input data\n",
        "  logits = state.apply_fn(params, data_input).squeeze(axis=-1)\n",
        "  pred_labels = (logits > 0).astype(jnp.float32)\n",
        "  # Calculate the loss and accuracy\n",
        "  loss = optax.sigmoid_binary_cross_entropy(logits, labels).mean()\n",
        "  acc = (pred_labels == labels).mean()\n",
        "  return loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhmWPv_J1vWf"
      },
      "source": [
        "* 試しに損失を計算させてみる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lr8WpPU1vWf"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(data_loader))\n",
        "calculate_loss_acc(model_state, model_state.params, batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CsrYdsZ1vWf"
      },
      "source": [
        "### JITコンパイルによる高速化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gYvScaY1vWf"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def train_step(state, batch):\n",
        "  # 勾配を計算する関数を得る\n",
        "  grad_fn = jax.value_and_grad(\n",
        "      calculate_loss_acc, # 損失を計算する関数\n",
        "      argnums=1, # 損失を計算する関数に渡す引数の位置\n",
        "      has_aux=True, # Function has additional outputs, here accuracy\n",
        "      )\n",
        "  # 勾配を計算\n",
        "  (loss, acc), grads = grad_fn(state, state.params, batch)\n",
        "  # 勾配と最適化アルゴリズムを使って状態を更新\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  return state, loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgkbNuYS1vWf"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def eval_step(state, batch):\n",
        "  # Determine the accuracy\n",
        "  _, acc = calculate_loss_acc(state, state.params, batch)\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQLz0jj21vWg"
      },
      "source": [
        "### 訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4hH-jCF1vWg"
      },
      "outputs": [],
      "source": [
        "train_dataset = XORDataset(size=2500, seed=42)\n",
        "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=numpy_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3YwR_tz1vWg"
      },
      "outputs": [],
      "source": [
        "def train_model(state, data_loader, num_epochs=100):\n",
        "  for epoch in tqdm(range(num_epochs)):\n",
        "    for batch in data_loader:\n",
        "      state, loss, acc = train_step(state, batch)\n",
        "      # ここにlogging用のコードを書いてもよい。\n",
        "  return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_NlI7Ht1vWg"
      },
      "outputs": [],
      "source": [
        "trained_model_state = train_model(model_state, train_data_loader, num_epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6__XcHZ1vWh"
      },
      "source": [
        "### 評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYDWg9-Z1vWh"
      },
      "outputs": [],
      "source": [
        "test_dataset = XORDataset(size=500, seed=123)\n",
        "test_data_loader = data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=128,\n",
        "    shuffle=False,\n",
        "    drop_last=False, # テストセットでは、これ、重要。\n",
        "    collate_fn=numpy_collate,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIeS-gOc1vWh"
      },
      "outputs": [],
      "source": [
        "def eval_model(state, data_loader):\n",
        "  all_accs, batch_sizes = [], []\n",
        "  for batch in data_loader:\n",
        "    batch_acc = eval_step(state, batch)\n",
        "    all_accs.append(batch_acc)\n",
        "    batch_sizes.append(batch[0].shape[0])\n",
        "  # Weighted average since some batches might be smaller\n",
        "  acc = sum([a*b for a,b in zip(all_accs, batch_sizes)]) / sum(batch_sizes)\n",
        "  print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGmqHiCc1vWh"
      },
      "outputs": [],
      "source": [
        "eval_model(trained_model_state, test_data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 訓練結果のシリアライズ\n",
        "* テキストファイルとして保存したい場合。"
      ],
      "metadata": {
        "id": "iunCuxo3NWVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import serialization\n",
        "dict_output = serialization.to_state_dict(trained_model_state.params)\n",
        "print(dict_output)"
      ],
      "metadata": {
        "id": "jicYvHEsNOGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcABoIuh1vWh"
      },
      "source": [
        "### モデルパラメータのバインディング\n",
        "* 今まで、モデルそのものと、モデルパラメータの値の特定の設定とを、別々に管理してきた。\n",
        "* しかし、これでは不便。\n",
        "* 以下のようにすれば、モデルのインスタンスを、特定のパラメータ値の設定へとbindできる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqLyODhJ1vWh"
      },
      "outputs": [],
      "source": [
        "trained_model = model.bind(trained_model_state.params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgBBj0RS1vWh"
      },
      "outputs": [],
      "source": [
        "data_input, labels = next(iter(data_loader))\n",
        "out = trained_model(data_input)  # No explicit parameter passing necessary anymore\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73of2WWl1vWi"
      },
      "source": [
        "* このほうが、PyTorchっぽい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhWu7C8t1vWi"
      },
      "source": [
        "### 分類境界の可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "rx-1dTe81vWi"
      },
      "outputs": [],
      "source": [
        "from matplotlib.colors import to_rgba\n",
        "\n",
        "def visualize_classification(model, data, label):\n",
        "  data_0 = data[label == 0]\n",
        "  data_1 = data[label == 1]\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "  plt.scatter(data_0[:,0], data_0[:,1], edgecolor=\"#333\", label=\"Class 0\")\n",
        "  plt.scatter(data_1[:,0], data_1[:,1], edgecolor=\"#333\", label=\"Class 1\")\n",
        "  plt.title(\"Dataset samples\")\n",
        "  plt.ylabel(r\"$x_2$\")\n",
        "  plt.xlabel(r\"$x_1$\")\n",
        "  plt.legend()\n",
        "\n",
        "  c0 = np.array(to_rgba(\"C0\"))\n",
        "  c1 = np.array(to_rgba(\"C1\"))\n",
        "  x1 = jnp.arange(-0.5, 1.5, step=0.01)\n",
        "  x2 = jnp.arange(-0.5, 1.5, step=0.01)\n",
        "  xx1, xx2 = jnp.meshgrid(x1, x2, indexing='ij')\n",
        "  model_inputs = np.stack([xx1, xx2], axis=-1)\n",
        "  logits = model(model_inputs)\n",
        "  preds = nn.sigmoid(logits)\n",
        "  output_image = (1 - preds) * c0[None,None] + preds * c1[None,None]\n",
        "  output_image = jax.device_get(output_image) # NumPyの配列に変換\n",
        "  plt.imshow(output_image, origin='lower', extent=(-0.5, 1.5, -0.5, 1.5))\n",
        "  plt.grid(False)\n",
        "  return fig\n",
        "\n",
        "visualize_classification(trained_model, dataset.data, dataset.label);"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VIGTMNdV8JeN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}